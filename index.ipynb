{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Neural Network Regularization\n", "\n", "This assessment covers building and training a `tf.keras` `Sequential` model, then applying regularization.  The dataset comes from a [\"don't overfit\" Kaggle competition](https://www.kaggle.com/c/dont-overfit-ii).  There are 300 features labeled 0-299, and a target called \"target\".  There are only 250 records total, meaning this is a very small dataset to be used with a neural network. \n", "\n", "_You can assume that the dataset has already been scaled._"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.model_selection import train_test_split\n", "\n", "import tensorflow as tf\n", "from tensorflow.keras import Sequential, regularizers\n", "from tensorflow.keras.layers import Dense, Dropout\n", "tf.logging.set_verbosity(tf.logging.ERROR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the cells below, the set of data has been split into a training and testing set and then fit to a neural network with two hidden layers. Run the cells below to see how well the model performs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "df = pd.read_csv(\"data.csv\")\n", "df.drop(\"id\", axis=1, inplace=True)\n", "\n", "X = df.drop(\"target\", axis=1)\n", "y = df[\"target\"]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020)\n", "X_train.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "def build_model():\n", "    \"\"\"\n", "    Creates and compiles a tf.keras Sequential model with two hidden layers\n", "    \"\"\"\n", "    # create classifier\n", "    classifier = Sequential()\n", "\n", "    # add input layer (shape is 300 because X has 300 features)\n", "    classifier.add(Dense(units=64, input_shape=(300,)))\n", "\n", "    # add hidden layers\n", "    classifier.add(Dense(units=64))\n", "    classifier.add(Dense(units=64))\n", "\n", "    # add output layer\n", "    classifier.add(Dense(units=1, activation='sigmoid'))\n", "\n", "    classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n", "    return classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "def fit_and_cross_validate_model(model_func, X, y):\n", "    \"\"\"\n", "    Given a function that builds a model and training X and y, validate the model based on\n", "    cross-validated train and test data\n", "    \"\"\"\n", "    train_scores = []\n", "    test_scores = []\n", "    for seed in [1,2,3,4,5]:\n", "        print(f\"######################## Training cross-validated model {seed} ###########################\")\n", "        X_train_cv, X_test_cv, y_train_cv, y_test_cv = \\\n", "            train_test_split(X, y, random_state=seed)\n", "        classifier = model_func()    \n", "        classifier.fit(X_train_cv, y_train_cv, epochs=5, verbose=1, batch_size=50, shuffle=False)\n", "        train_scores.append(accuracy_score(y_train_cv, classifier.predict_classes(X_train_cv)))\n", "        test_scores.append(accuracy_score(y_test_cv, classifier.predict_classes(X_test_cv)))\n", "    print(\"############################## Model evaluation #####################################\")\n", "    print(\"Approximate training accuracy:\")\n", "    print(np.mean(train_scores), \"+/-\", np.std(train_scores))\n", "    print(\"Approximate testing accuracy:\")\n", "    print(np.mean(test_scores), \"+/-\", np.std(test_scores))\n", "    return train_scores, test_scores"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "fit_and_cross_validate_model(build_model, X_train, y_train);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Modify the code below to use regularization\n", "\n", "\n", "The model appears to be overfitting. To deal with this overfitting, modify the code below to include regularization in the model. You can add L1, L2, both L1 and L2, or dropout regularization."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hint: these might be helpful\n", "\n", " - [`Dense` layer documentation](https://keras.io/layers/core/)\n", " - [`regularizers` documentation](https://keras.io/regularizers/)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_model_with_regularization():\n", "    \"\"\"\n", "    Creates and compiles a tf.keras Sequential model with two hidden layers\n", "    This time regularization has been added\n", "    \"\"\"\n", "    # create classifier\n", "    classifier = Sequential()\n", "\n", "    # add input layer\n", "    classifier.add(Dense(units=64, input_shape=(300,)))\n", "\n", "    # add hidden layers\n", "    \n", "    # YOUR CODE HERE\n", "\n", "    # add output layer\n", "    classifier.add(Dense(units=1, activation='sigmoid'))\n", "\n", "    classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n", "    return classifier\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "fit_and_cross_validate_model(build_model_with_regularization, X_train, y_train);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Based on the cross-validated scores, did the regularization you performed help prevent overfitting? Is the first or the second model better?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your written answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Now, evaluate both models on the holdout set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "classifier_1 = build_model()\n", "classifier_1.fit(X_train, y_train, epochs=5, verbose=1, batch_size=50, shuffle=False)\n", "\n", "classifier_2 = build_model_with_regularization()\n", "classifier_2.fit(X_train, y_train, epochs=5, verbose=1, batch_size=50, shuffle=False)\n", "\n", "print(\"Accuracy score without regularization:\", accuracy_score(y_test, classifier_1.predict_classes(X_test)))\n", "print(\"Accuracy score with regularization:\", accuracy_score(y_test, classifier_2.predict_classes(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2) Explain how regularization is related to the bias/variance tradeoff within Neural Networks and how it's related to the results you just achieved in the training and test accuracies of the previous models. What does regularization change in the training process (be specific to what is being regularized and how it is regularizing)?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3) How might L1  and dropout regularization change a neural network's architecture?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.7"}}, "nbformat": 4, "nbformat_minor": 4}