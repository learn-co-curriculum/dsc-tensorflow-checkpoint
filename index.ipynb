{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a405f9c797c90edb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Neural Network Regularization\n",
    "\n",
    "This assessment covers building and training a `tf.keras` `Sequential` model, then applying regularization.  The dataset comes from a [\"don't overfit\" Kaggle competition](https://www.kaggle.com/c/dont-overfit-ii).  There are 300 features labeled 0-299, and a target called \"target\".  There are only 250 records total, meaning this is a very small dataset to be used with a neural network. \n",
    "\n",
    "_You can assume that the dataset has already been scaled._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:46:28.793582Z",
     "start_time": "2020-11-04T16:46:24.326301Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ab18aba8319e5bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, regularizers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f13775b02d6a5629",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the cells below, the set of data has been split into a training and testing set and then fit to a neural network with two hidden layers. Run the cells below to see how well the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:46:39.982594Z",
     "start_time": "2020-11-04T16:46:39.912267Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-102893d9e04206ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2020)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:46:41.053374Z",
     "start_time": "2020-11-04T16:46:41.049347Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bf74656fbaa659c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"\n",
    "    Creates and compiles a tf.keras Sequential model with two hidden layers\n",
    "    \"\"\"\n",
    "    # create classifier\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # add input layer (shape is 300 because X has 300 features)\n",
    "    classifier.add(Dense(units=64, input_shape=(300,)))\n",
    "\n",
    "    # add hidden layers\n",
    "    classifier.add(Dense(units=64))\n",
    "    classifier.add(Dense(units=64))\n",
    "\n",
    "    # add output layer\n",
    "    classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:46:41.980601Z",
     "start_time": "2020-11-04T16:46:41.976757Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60c0d8e93d2e7345",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "def fit_and_cross_validate_model(model_func, X, y):\n",
    "    \"\"\"\n",
    "    Given a function that builds a model and training X and y, validate the model based on\n",
    "    cross-validated train and test data\n",
    "    \"\"\"\n",
    "    keras_classifier = KerasClassifier(model_func, epochs=5, batch_size=50, verbose=1, shuffle=False)\n",
    "    \n",
    "    print(\"######################## Training cross-validated models ###########################\")\n",
    "    cross_val_scores = cross_val_score(keras_classifier, X, y, cv=5)\n",
    "    \n",
    "    print(\"########################### Training on full X_train ###############################\")\n",
    "    keras_classifier.fit(X, y)\n",
    "    \n",
    "    print(\"############################### Evaluation report ##################################\")\n",
    "    \n",
    "    print(\"Approximate training accuracy:\")\n",
    "    print(accuracy_score(y, keras_classifier.predict(X)))\n",
    "    \n",
    "    print(\"Approximate testing accuracy:\")\n",
    "    print(np.mean(cross_val_scores), \"+/-\", np.std(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:46:46.476915Z",
     "start_time": "2020-11-04T16:46:42.896428Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3768408c70031b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "fit_and_cross_validate_model(build_model, X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6e6592358923b0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  1) **Modify the code below to use regularization.**\n",
    "\n",
    "\n",
    "The model appears to be overfitting. To deal with this overfitting, modify the code below to include regularization in the model. You can add L1, L2, both L1 and L2, or dropout regularization.\n",
    "\n",
    "Hint: these might be helpful\n",
    "\n",
    " - [`Dense` layer documentation](https://keras.io/layers/core/)\n",
    " - [`regularizers` documentation](https://keras.io/regularizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:48:46.721530Z",
     "start_time": "2020-11-04T16:48:46.715001Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-143a65663b1d4c26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_model_with_regularization():\n",
    "    \"\"\"\n",
    "    Creates and compiles a tf.keras Sequential model with two hidden layers\n",
    "    This time regularization has been added\n",
    "    \"\"\"\n",
    "    # create classifier\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # add input layer\n",
    "    classifier.add(Dense(units=64, input_shape=(300,)))\n",
    "\n",
    "    # add hidden layers\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # add output layer\n",
    "    classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "def build_model_with_regularization():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=64, input_shape=(300,), kernel_regularizer=regularizers.l2(0.0000000000000001)))\n",
    "    # they might add a kernel regularizer\n",
    "    classifier.add(Dense(units=64, kernel_regularizer=regularizers.l2(0.0000000000000001)))\n",
    "    # they might add a dropout layer\n",
    "    classifier.add(Dropout(0.8))\n",
    "    classifier.add(Dense(units=64, kernel_regularizer=regularizers.l2(0.0000000000000001)))\n",
    "    classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "    classifier.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:48:47.310049Z",
     "start_time": "2020-11-04T16:48:47.265185Z"
    },
    "code_folding": [],
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-45429cad9bc0ca12",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "model_with_regularization = build_model_with_regularization()\n",
    "assert type(model_with_regularization) == tf.python.keras.engine.sequential.Sequential\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "def check_regularization(model):\n",
    "    regularization_count = 0\n",
    "    for layer in model.get_config()['layers']:\n",
    "        if 'kernel_regularizer' in layer['config']:\n",
    "            if layer['config'].get('kernel_regularizer'):\n",
    "                regularization_count += 1\n",
    "    if regularization_count:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "score = .3\n",
    "\n",
    "if check_regularization(model_with_regularization):\n",
    "    score += .7\n",
    "    \n",
    "score\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbd35235436728db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2) Written response:\n",
    "\n",
    ">Based on the cross-validated scores, did the regularization you performed help prevent overfitting? Is the first or the second model better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-32668685f07349b1",
     "locked": false,
     "points": 1.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "===BEGIN MARK SCHEME===\n",
    "\n",
    "It may or may not have prevented overfitting, depending on random elements\n",
    "within the neural net as well as their choice of regularization technique\n",
    "\n",
    "(TensorFlow + random seeding is not fully possible in a Jupyter Notebook)\n",
    "\n",
    "The student should interpret the numbers they have\n",
    "\n",
    "In the example given above, a reasonable answer would be:\n",
    "The regularization is helping to prevent overfitting, but it also might be\n",
    "causing some underfitting.  The train and test accuracy are more similar to\n",
    "each other, but the test accuracy also got slightly worse.  I think the\n",
    "original model is better, even though it is overfitting.\n",
    "\n",
    "It is also very likely that they will not have applied strong enough\n",
    "regularization to make a difference, so the scores for the two models will\n",
    "mainly differ based on random seeds\n",
    "\n",
    "===END MARK SCHEME==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, evaluate both models on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:48:51.696097Z",
     "start_time": "2020-11-04T16:48:50.648823Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-761e0525b4f93f92",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "classifier_1 = build_model()\n",
    "classifier_1.fit(X_train, y_train, epochs=5, verbose=1, batch_size=50, shuffle=False)\n",
    "\n",
    "classifier_2 = build_model_with_regularization()\n",
    "classifier_2.fit(X_train, y_train, epochs=5, verbose=1, batch_size=50, shuffle=False)\n",
    "\n",
    "print(\"Accuracy score without regularization:\", accuracy_score(y_test, classifier_1.predict_classes(X_test)))\n",
    "print(\"Accuracy score with regularization:\", accuracy_score(y_test, classifier_2.predict_classes(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc4c4118bde04c89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "###  3) Written response:\n",
    ">Explain how regularization is related to the bias/variance tradeoff within Neural Networks and how it's related to the results you just achieved in the training and test accuracies of the previous models. What does regularization change in the training process (be specific to what is being regularized and how it is regularizing)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-24b558e74ad7a68e",
     "locked": false,
     "points": 1.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "===BEGIN MARK SCHEME===\n",
    "\n",
    "Regularization helps prevent over fitting by adding penalty terms to the cost function. \n",
    "This prevents any one feature to having too much importance in a model.  One feature\n",
    "having too much importance can lead to overfitting (high variance).  On the other hand,\n",
    "too much regularization can lead to underfitting (high bias).\n",
    "\n",
    "The specific regularization used in the solution code is:\n",
    "L2 regularization: penalizes weight matrices for being too large\n",
    "Dropout regularization: a random subset of nodes are ignored\n",
    "\n",
    "The current dataset is very small to be used with a neural network, so it's possible that\n",
    "we don't actually have enough information to create a good, generalizable model\n",
    "\n",
    "===END MARK SCHEME==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-467a64b37776e15f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4) Written response: \n",
    "\n",
    ">How might L1  and dropout regularization change a neural network's architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-159e32409d94d9ab",
     "locked": false,
     "points": 1.25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "===BEGIN MARK SCHEME===\n",
    "\n",
    "L1 and dropout regularization may eliminate connections between nodes entirely.\n",
    "\n",
    "===END MARK SCHEME==="
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
